---
title: "DAT 612 - Final Project Proposal"
author: "sufian"
date: "7/5/2020"
output: html_document
---

# Introduction

------------------------------------------------------------------------------------------------------------------

\clearpage

The goal is to evaluate and create an end-to-end recommender system against yet to be determined datasets (probably the movielens data set if time is too constrained) and determine to which algorithms produce the best predictive models.

To that end, the project will attempt multiple recommenders libraries to determine which is most effective. And within data analysis; comparisons of accuracy metrics like RSMEs, ROC and Precision-to-Recall cureves will be utilized to determine which ones produces the best result.  The traditional IBCF and UBCF methods will be implemented and tested for accuracies and performance against Pythonâ€™s Scikit-Learn packaged KNN and SVD algorithms. In addition (time permits), a Spark-based Alternating least squares (ALS) algorithm will also be added to see if performance could be improved in the Spark environment. 

The following steps will be applied throughout the project:

- Training and test split of the datasets
- Hyper-parameter tuning via cross-validation
- Implement the different algorithms/models 
- Comparing accuracy across the datasets per the different algorithms
- Predictive accuracies will rely on Root mean squared error (RMSE), Mean square error (MSE) and Mean absolute error (MAE). Comparative analysis will be use to determine which models gives the best results via learning/accuracy curves and computational speeds.

------------------------------------------------------------------------------------------------------------------

\clearpage

![Fig1: Process Work flow](https://github.com/ssufian/DAT-612/blob/master/Projects/Final%20Project%20Proposal%20Workflow.JPG?raw=true) 

------------------------------------------------------------------------------------------------------------------

\clearpage

# ETLs

Step 1: We will first import the dataset from GitHub, clean the datasets, and perform data exploration. Statistical and visual will be included.

Step 2/3: Transform and/or combine the datasets for further analysis if necessary before splitting it into training and testing sets. Finally, when data is deem "cleaned", it will be loaded either into Python or R.

Step 4: Introduced and implement the User-Based Collaborative Filtering (UBCF), Item-Based Collaborative Filtering (IBCF), Singular Value Decomposition (SVD), and KNN algorithms with different parameters (e.g. similarity methods, normalization techniques).

Step5: Evaluate the model performance and accuracy using the metrics RMSE, MAE, MSE, ROC Curve/AUC, and Precision-Recall.  These metrics will in turn guide in the final recommender system to be build for production; model with the best overall accuracy and computational performance.

------------------------------------------------------------------------------------------------------------------

\clearpage

Reference:

(1) BUILDING_A_RECOMMENDATION_SYSTEM_WITH_R by Suresh K. Gorakala & Michele Usuelli


------------------------------------------------------------------------------------------------------------------

\clearpage

